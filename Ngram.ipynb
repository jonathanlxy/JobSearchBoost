{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = pd.read_csv( 'unique_jobs.csv', encoding = 'utf-8' )\n",
    "search_terms = jobs.search_term.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine job descriptions with skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bind_desc_skill( job ):\n",
    "    if job[1] is np.nan:\n",
    "        doc = job[0]\n",
    "    else:\n",
    "        doc = ' '.join( job )\n",
    "    return doc.replace( '\\n', ' ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs['desc_skill'] = jobs[ ['job_description', 'skills'] ].apply( bind_desc_skill, axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_by_term = {}\n",
    "for term in jobs.search_term.unique():\n",
    "    jobs_by_term[term] = jobs[ jobs.search_term == term ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top N grams for job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class unigram( object ):\n",
    "    def __init__(self, doc, stem = True ):\n",
    "        # doc to lowercase\n",
    "        low_doc = doc.lower()\n",
    "        # Punctuation removal\n",
    "        tokenizer = RegexpTokenizer( r'\\w+' )\n",
    "        tokens_P = tokenizer.tokenize( low_doc )\n",
    "        # Stopwords removal\n",
    "        custom_stopwords = stopwords.words( 'english' ) + ['nbsp', 'amp']\n",
    "        tokens_PS = [ token for token in tokens_P if token not in custom_stopwords ]\n",
    "        # Stemming\n",
    "        if stem == True:\n",
    "            stemmer = PorterStemmer()\n",
    "            final_tokens = [ stemmer.stem( token ) for token in tokens_PS ]\n",
    "        else:\n",
    "            final_tokens = tokens_PS\n",
    "        # FreqDist\n",
    "        freq = nltk.FreqDist( final_tokens )\n",
    "        # ====================================\n",
    "        self.tokens  = final_tokens\n",
    "        self.freq    = freq\n",
    "        self.total_n = len( freq )\n",
    "        \n",
    "    def top_n( self, n ):\n",
    "        return self.freq.most_common( n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bind_string( string_list ):\n",
    "    one_string = unicode( '' )\n",
    "    for s in string_list:\n",
    "        one_string += ' ' + s\n",
    "    return one_string\n",
    "\n",
    "desc_by_term = {} # Each search term with one single string\n",
    "for term in jobs.search_term.unique():\n",
    "    desc_by_term[term] = bind_string( jobs_by_term[term].desc_skill )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "term = 'Data+Scientist'\n",
    "# Tokenize job desc\n",
    "uni_gram_stem = unigram( desc_by_term[ term ], stem = True )\n",
    "bi_gram = nltk.FreqDist( nltk.bigrams( uni_gram_stem.tokens ) )\n",
    "tri_gram = nltk.FreqDist( nltk.trigrams( uni_gram_stem.tokens ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni</th>\n",
       "      <th>Bi</th>\n",
       "      <th>Tri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(data, 5057)</td>\n",
       "      <td>((big, data), 454)</td>\n",
       "      <td>((equal, opportun, employ), 93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(experi, 2823)</td>\n",
       "      <td>((year, experi), 359)</td>\n",
       "      <td>((new, york, citi), 89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(work, 2213)</td>\n",
       "      <td>((data, scienc), 319)</td>\n",
       "      <td>((5, year, experi), 85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(team, 1938)</td>\n",
       "      <td>((new, york), 291)</td>\n",
       "      <td>((without, regard, race), 78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(busi, 1912)</td>\n",
       "      <td>((comput, scienc), 289)</td>\n",
       "      <td>((degre, comput, scienc), 78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(develop, 1821)</td>\n",
       "      <td>((machin, learn), 275)</td>\n",
       "      <td>((race, color, religion), 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(manag, 1751)</td>\n",
       "      <td>((commun, skill), 251)</td>\n",
       "      <td>((regard, race, color), 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(analyt, 1639)</td>\n",
       "      <td>((e, g), 201)</td>\n",
       "      <td>((2, year, experi), 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(skill, 1208)</td>\n",
       "      <td>((data, scientist), 194)</td>\n",
       "      <td>((sexual, orient, gender), 69)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(product, 1146)</td>\n",
       "      <td>((experi, work), 189)</td>\n",
       "      <td>((orient, gender, ident), 69)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Uni                        Bi                              Tri\n",
       "0     (data, 5057)        ((big, data), 454)  ((equal, opportun, employ), 93)\n",
       "1   (experi, 2823)     ((year, experi), 359)          ((new, york, citi), 89)\n",
       "2     (work, 2213)     ((data, scienc), 319)          ((5, year, experi), 85)\n",
       "3     (team, 1938)        ((new, york), 291)    ((without, regard, race), 78)\n",
       "4     (busi, 1912)   ((comput, scienc), 289)    ((degre, comput, scienc), 78)\n",
       "5  (develop, 1821)    ((machin, learn), 275)    ((race, color, religion), 75)\n",
       "6    (manag, 1751)    ((commun, skill), 251)      ((regard, race, color), 74)\n",
       "7   (analyt, 1639)             ((e, g), 201)          ((2, year, experi), 70)\n",
       "8    (skill, 1208)  ((data, scientist), 194)   ((sexual, orient, gender), 69)\n",
       "9  (product, 1146)     ((experi, work), 189)    ((orient, gender, ident), 69)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( { 'Uni': uni_gram_stem.top_n( top_n ),\n",
    "                'Bi' : bi_gram.most_common( top_n ),\n",
    "                'Tri': tri_gram.most_common( top_n )\n",
    "              } )[['Uni', 'Bi', 'Tri']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
